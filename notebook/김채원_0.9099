{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lFQ-gpjnN_m"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "drive.mount('/content/drive')\n",
        "!tar -xvf /content/drive/MyDrive/data.tar.gz > /dev/null\n",
        "!pip install timm\n",
        "!pip install augraphy\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from augraphy import *\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import NAdam\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.HorizontalFlip(p=0.35),\n",
        "    A.VerticalFlip(p=0.35),\n",
        "    A.OneOf([A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=(15, 25)),A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=(-15, -25))], p=0.3),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(height=512, width=512),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "train_augraphy = AugraphyPipeline([ShadowCast(shadow_opacity_range=(0,0.35)), LightingGradient(), LowLightNoise(p = 0.5)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, csv, path, transform=None, augraphy=None):\n",
        "        self.df = pd.read_csv(csv).values\n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "        self.augraphy = augraphy\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        name, target = self.df[idx]\n",
        "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
        "        if img.shape[1] > img.shape[0]:\n",
        "            img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
        "        if self.augraphy:\n",
        "            img = self.augraphy(img)\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "        return img, target\n",
        "\n",
        "model = timm.create_model('maxvit_xlarge_tf_512', pretrained=True, num_classes=17).to(device)\n",
        "optimizer = NAdam(model.parameters(), lr=5e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for _ in range(30):\n",
        "    model.train()\n",
        "    train_dataset = ImageDataset(\"/content/data/train.csv\", \"/content/data/train/\", transform=train_transform, augraphy= train_augraphy)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
        "    preds_list, targets_list = [], []\n",
        "    for image, targets in tqdm(train_loader):\n",
        "        image, targets = image.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(image)\n",
        "        loss = loss_fn(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
        "        targets_list.extend(targets.detach().cpu().numpy())\n",
        "    print(f1_score(targets_list, preds_list, average=\"macro\"))\n",
        "\n",
        "test_dataset = ImageDataset(\"/content/data/sample_submission.csv\", \"/content/data/test/\", transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
        "preds_list = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for image, _ in tqdm(test_loader):\n",
        "        preds = model(image.to(device))\n",
        "        preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n",
        "pd.DataFrame({'ID': test_dataset.df[:, 0], 'target': preds_list}).to_csv(\"sub.csv\", index=False)"
      ],
      "metadata": {
        "id": "6uQpkxi1mUxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}